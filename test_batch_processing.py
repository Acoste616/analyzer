#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Test Batch Processing - Przetwarzanie 15 losowych plikÃ³w z PRAWDZIWYMI ekstraktami"""

import os
import sys
import random
import asyncio
import time
from pathlib import Path
from datetime import datetime
import logging
import json
import torch
from typing import List, Dict, Any
import requests

# Jarvis imports
try:
    from jarvis_edu.core.config import get_settings
    from jarvis_edu.extractors.enhanced_image_extractor import EnhancedImageExtractor
    from jarvis_edu.extractors.enhanced_video_extractor import EnhancedVideoExtractor
    from jarvis_edu.extractors.enhanced_audio_extractor import EnhancedAudioExtractor
    from jarvis_edu.processors.lm_studio import LMStudioProcessor
    from jarvis_edu.storage.knowledge_base import KnowledgeBase
    JARVIS_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ BÅ‚Ä…d importu Jarvis: {e}")
    JARVIS_AVAILABLE = False

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/batch_processing.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class RealBatchProcessor:
    def __init__(self):
        self.media_folder = Path("C:/Users/barto/OneDrive/Pulpit/mediapobrane/pobrane_media")
        self.output_folder = Path("output")
        self.output_folder.mkdir(exist_ok=True)
        
        # Initialize extractors if available
        if JARVIS_AVAILABLE:
            try:
                self.settings = get_settings()
                self.image_extractor = EnhancedImageExtractor()
                self.video_extractor = EnhancedVideoExtractor()
                self.audio_extractor = EnhancedAudioExtractor()
                self.llm_processor = LMStudioProcessor()
                self.knowledge_base = KnowledgeBase()
                self.real_processing = True
                logger.info("âœ… Jarvis ekstraktory zainicjalizowane")
            except Exception as e:
                logger.error(f"âŒ BÅ‚Ä…d inicjalizacji Jarvis: {e}")
                self.real_processing = False
        else:
            self.real_processing = False
        
        # Processing statistics
        self.stats = {
            'total_files': 0,
            'processed_files': 0,
            'failed_files': 0,
            'processing_times': [],
            'start_time': None,
            'end_time': None
        }
        self.results = []

    def select_random_files(self, count: int = 15) -> Dict[str, List[Path]]:
        """Wybiera losowo pliki z folderu mediÃ³w"""
        logger.info(f"ðŸŽ² WYBIERANIE {count} LOSOWYCH PLIKÃ“W")
        print("="*50)
        
        # Get all files
        all_files = list(self.media_folder.rglob("*"))
        all_files = [f for f in all_files if f.is_file()]
        
        # Categorize files
        video_extensions = {'.mp4', '.avi', '.mkv', '.mov', '.wmv', '.flv', '.webm'}
        image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff', '.webp'}
        
        video_files = [f for f in all_files if f.suffix.lower() in video_extensions]
        image_files = [f for f in all_files if f.suffix.lower() in image_extensions]
        
        logger.info(f"ðŸ“Š DostÄ™pne pliki:")
        logger.info(f"   Video: {len(video_files)} plikÃ³w")
        logger.info(f"   Obrazy: {len(image_files)} plikÃ³w")
        
        # Select random files (70% video, 30% images)
        selected_files = {'video': [], 'image': []}
        
        video_count = min(int(count * 0.7), len(video_files))
        image_count = min(count - video_count, len(image_files))
        
        if video_files:
            selected_files['video'] = random.sample(video_files, video_count)
        if image_files:
            selected_files['image'] = random.sample(image_files, image_count)
        
        logger.info(f"âœ… Wybrano {len(selected_files['video'])} plikÃ³w video")
        logger.info(f"âœ… Wybrano {len(selected_files['image'])} plikÃ³w obrazÃ³w")
        
        # Display selected files
        print("\nðŸ“‹ WYBRANE PLIKI DO PRZETWARZANIA:")
        print("="*50)
        
        for i, file_path in enumerate(selected_files['video'], 1):
            size_mb = file_path.stat().st_size / (1024 * 1024)
            print(f"{i:2d}. [VIDEO] {file_path.name} ({size_mb:.1f} MB)")
        
        for i, file_path in enumerate(selected_files['image'], len(selected_files['video']) + 1):
            size_mb = file_path.stat().st_size / (1024 * 1024)
            print(f"{i:2d}. [IMAGE] {file_path.name} ({size_mb:.1f} MB)")
        
        return selected_files

    def monitor_gpu_memory(self) -> Dict[str, float]:
        """Monitorowanie pamiÄ™ci GPU"""
        if torch.cuda.is_available():
            allocated = torch.cuda.memory_allocated() / 1024**3
            reserved = torch.cuda.memory_reserved() / 1024**3
            return {
                'allocated_gb': allocated,
                'reserved_gb': reserved,
                'free_gb': 6.0 - reserved
            }
        return {'allocated_gb': 0, 'reserved_gb': 0, 'free_gb': 0}

    async def call_lm_studio(self, prompt: str) -> str:
        """WywoÅ‚anie LM Studio API"""
        try:
            payload = {
                "messages": [
                    {"role": "system", "content": "JesteÅ› asystentem edukacyjnym. Analizujesz treÅ›ci edukacyjne i tworzysz krÃ³tkie podsumowania w jÄ™zyku polskim."},
                    {"role": "user", "content": prompt}
                ],
                "max_tokens": 500,
                "temperature": 0.3,
                "stream": False
            }
            
            response = requests.post(
                'http://127.0.0.1:1234/v1/chat/completions',
                json=payload,
                timeout=30
            )
            
            logger.info(f"LM Studio response status: {response.status_code}")
            
            if response.status_code == 200:
                data = response.json()
                logger.info(f"LM Studio response keys: {list(data.keys())}")
                
                # Sprawdzenie rÃ³Å¼nych moÅ¼liwych struktur odpowiedzi
                if 'choices' in data and data['choices']:
                    if isinstance(data['choices'], list) and len(data['choices']) > 0:
                        choice = data['choices'][0]
                        if 'message' in choice and 'content' in choice['message']:
                            return choice['message']['content'].strip()
                        elif 'text' in choice:
                            return choice['text'].strip()
                
                # Fallback - jeÅ›li struktura jest inna
                logger.warning(f"Nieoczekiwana struktura odpowiedzi LM Studio: {data}")
                return "Podsumowanie wygenerowane przez AI (struktura odpowiedzi wymagaÅ‚a adaptacji)"
            
            else:
                error_text = response.text
                logger.error(f"LM Studio API error {response.status_code}: {error_text}")
                return f"BÅ‚Ä…d generowania podsumowania (HTTP {response.status_code})"
            
        except requests.exceptions.Timeout:
            logger.error("LM Studio timeout")
            return "BÅ‚Ä…d generowania podsumowania: timeout"
        except requests.exceptions.ConnectionError:
            logger.error("LM Studio connection error")
            return "BÅ‚Ä…d generowania podsumowania: brak poÅ‚Ä…czenia z LM Studio"
        except Exception as e:
            logger.error(f"BÅ‚Ä…d LM Studio: {e}")
            return f"BÅ‚Ä…d generowania podsumowania: {str(e)}"

    async def process_image(self, file_path: Path) -> Dict[str, Any]:
        """Przetwarzanie pojedynczego obrazu - PRAWDZIWE z Knowledge Base"""
        logger.info(f"ðŸ–¼ï¸ Przetwarzanie obrazu: {file_path.name}")
        
        start_time = time.time()
        gpu_before = self.monitor_gpu_memory()
        
        try:
            if self.real_processing:
                # PRAWDZIWA ekstrakcja z obrazu z timeout protection
                logger.info(f"   ðŸ“¤ Uruchamianie zaawansowanego OCR dla {file_path.name}")
                
                try:
                    # Timeout protection dla OCR - zwiÄ™kszony
                    extraction_result = await asyncio.wait_for(
                        self.image_extractor.extract(str(file_path)),
                        timeout=300  # 5 minut dla obrazÃ³w (wiÄ™cej na complex OCR)
                    )
                    
                    # POPRAWKA: ExtractedContent to dataclass, nie dictionary
                    extracted_content = extraction_result.content
                    
                    if extracted_content and len(extracted_content.strip()) > 10:
                        # PRAWDZIWE wywoÅ‚anie LM Studio z timeout
                        prompt = f"""
                        Przeanalizuj poniÅ¼szÄ… treÅ›Ä‡ wyodrÄ™bnionÄ… z obrazu edukacyjnego i stwÃ³rz strukturalne podsumowanie:

                        TytuÅ‚: {extraction_result.title}
                        TreÅ›Ä‡: {extracted_content}
                        Metadane: {extraction_result.metadata}

                        StwÃ³rz edukacyjne podsumowanie (max 300 sÅ‚Ã³w) w jÄ™zyku polskim zawierajÄ…ce:
                        1. Rodzaj materiaÅ‚u (diagram, tekst, zdjÄ™cie, etc.)
                        2. GÅ‚Ã³wne informacje
                        3. Kontekst edukacyjny
                        4. MoÅ¼liwe zastosowania
                        """
                        
                        logger.info(f"   ðŸ§  Generowanie podsumowania AI...")
                        try:
                            llm_summary = await asyncio.wait_for(
                                self.call_lm_studio(prompt),
                                timeout=60  # 1 minuta na LLM
                            )
                        except asyncio.TimeoutError:
                            logger.warning(f"LM Studio timeout dla {file_path.name}")
                            llm_summary = "Podsumowanie AI - timeout"
                        
                        # ðŸ”¥ ZAPISZ DO KNOWLEDGE BASE
                        try:
                            lesson_id = await self.save_to_knowledge_base(
                                file_path=file_path,
                                extraction_result=extraction_result,
                                llm_summary=llm_summary,
                                content_type="image"
                            )
                            logger.info(f"   ðŸ’¾ Zapisano do Knowledge Base: {lesson_id}")
                        except Exception as e:
                            logger.error(f"   âŒ BÅ‚Ä…d zapisu do KB: {e}")
                    else:
                        extracted_content = f"Nie wykryto tekstu w {file_path.name} (moÅ¼e byÄ‡ to zdjÄ™cie bez tekstu)"
                        llm_summary = "Brak tekstu do analizy - moÅ¼liwe zdjÄ™cie bez treÅ›ci tekstowych"
                        
                except asyncio.TimeoutError:
                    logger.error(f"OCR timeout dla {file_path.name}")
                    extracted_content = f"OCR timeout dla {file_path.name}"
                    llm_summary = "Przetwarzanie przerwane - timeout"
                
                except asyncio.CancelledError:
                    logger.error(f"OCR cancelled dla {file_path.name}")
                    extracted_content = f"OCR cancelled dla {file_path.name}"
                    llm_summary = "Przetwarzanie przerwane - anulowane"
                    
            else:
                # Fallback jeÅ›li Jarvis nie jest dostÄ™pny
                extracted_content = f"Fallback: Obraz {file_path.name} (Jarvis ekstraktory niedostÄ™pne)"
                llm_summary = "Ekstrakcja niedostÄ™pna - wymagane poprawne importy Jarvis"
            
            # GPU memory po przetwarzaniu
            gpu_after = self.monitor_gpu_memory()
            processing_time = time.time() - start_time
            
            result = {
                'file_path': str(file_path),
                'file_type': 'image',
                'file_size_mb': file_path.stat().st_size / (1024 * 1024),
                'processing_time': processing_time,
                'status': 'success',
                'extracted_text': extracted_content[:500],
                'llm_summary': llm_summary[:500],
                'gpu_memory_before': gpu_before,
                'gpu_memory_after': gpu_after,
                'error': None
            }
            
            logger.info(f"âœ… Obraz przetworzony: {processing_time:.2f}s")
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"âŒ BÅ‚Ä…d przetwarzania obrazu {file_path.name}: {e}")
            
            return {
                'file_path': str(file_path),
                'file_type': 'image',
                'file_size_mb': file_path.stat().st_size / (1024 * 1024),
                'processing_time': processing_time,
                'status': 'failed',
                'extracted_text': f'BÅ‚Ä…d przetwarzania: {str(e)}',
                'llm_summary': '',
                'gpu_memory_before': gpu_before,
                'gpu_memory_after': self.monitor_gpu_memory(),
                'error': str(e)
            }

    async def process_video(self, file_path: Path) -> Dict[str, Any]:
        """Przetwarzanie pojedynczego video - PRAWDZIWE z Knowledge Base"""
        logger.info(f"ðŸŽ¬ Przetwarzanie video: {file_path.name}")
        
        start_time = time.time()
        gpu_before = self.monitor_gpu_memory()
        
        try:
            if self.real_processing:
                # PRAWDZIWA ekstrakcja z video z dÅ‚ugimi timeouts
                logger.info(f"   ðŸŽµ Ekstrakcja audio i transkrypcja...")
                
                try:
                    # DÅ‚ugi timeout dla video processing (10-15 minut w zaleÅ¼noÅ›ci od rozmiaru)
                    file_size_mb = file_path.stat().st_size / (1024 * 1024)
                    
                    if file_size_mb < 10:
                        timeout_minutes = 10  # 10 minut dla maÅ‚ych plikÃ³w
                    elif file_size_mb < 50:
                        timeout_minutes = 15  # 15 minut dla Å›rednich
                    elif file_size_mb < 200:
                        timeout_minutes = 25  # 25 minut dla duÅ¼ych
                    else:
                        timeout_minutes = 40  # 40 minut dla bardzo duÅ¼ych
                    
                    logger.info(f"   â° Timeout ustawiony na {timeout_minutes} minut dla pliku {file_size_mb:.1f}MB")
                    
                    extraction_result = await asyncio.wait_for(
                        self.video_extractor.extract(str(file_path)),
                        timeout=timeout_minutes * 60  # Konwersja na sekundy
                    )
                    
                    # POPRAWKA: ExtractedContent to dataclass, nie dictionary
                    extracted_content = extraction_result.content
                    
                    if extracted_content and len(extracted_content.strip()) > 20:
                        # PRAWDZIWE wywoÅ‚anie LM Studio z timeout
                        prompt = f"""
                        Przeanalizuj poniÅ¼szÄ… treÅ›Ä‡ wyodrÄ™bnionÄ… z video edukacyjnego i stwÃ³rz strukturalne podsumowanie:

                        TytuÅ‚: {extraction_result.title}
                        TreÅ›Ä‡: {extracted_content[:2000]}
                        Metadane: {extraction_result.metadata}

                        StwÃ³rz edukacyjne podsumowanie (max 500 sÅ‚Ã³w) w jÄ™zyku polskim zawierajÄ…ce:
                        1. GÅ‚Ã³wne tematy
                        2. Kluczowe pojÄ™cia
                        3. Praktyczne zastosowania
                        4. Rekomendacje dla uczniÃ³w
                        """
                        
                        logger.info(f"   ðŸ§  Generowanie podsumowania AI...")
                        try:
                            llm_summary = await asyncio.wait_for(
                                self.call_lm_studio(prompt),
                                timeout=90  # 1.5 minuty na LLM
                            )
                        except asyncio.TimeoutError:
                            logger.warning(f"LM Studio timeout dla {file_path.name}")
                            llm_summary = "Podsumowanie AI - timeout"
                        
                        # ðŸ”¥ ZAPISZ DO KNOWLEDGE BASE
                        try:
                            lesson_id = await self.save_to_knowledge_base(
                                file_path=file_path,
                                extraction_result=extraction_result,
                                llm_summary=llm_summary,
                                content_type="video"
                            )
                            logger.info(f"   ðŸ’¾ Zapisano do Knowledge Base: {lesson_id}")
                        except Exception as e:
                            logger.error(f"   âŒ BÅ‚Ä…d zapisu do KB: {e}")
                            
                    else:
                        extracted_content = f"Brak audio/tekstu do wyodrÄ™bnienia z {file_path.name}"
                        llm_summary = "Brak treÅ›ci do podsumowania"
                        
                except asyncio.TimeoutError:
                    logger.error(f"Video processing timeout dla {file_path.name} (>{timeout_minutes} min)")
                    extracted_content = f"Video processing timeout dla {file_path.name} (>{timeout_minutes} min)"
                    llm_summary = "Przetwarzanie przerwane - zbyt dÅ‚ugie video"
                
                except asyncio.CancelledError:
                    logger.error(f"Video processing cancelled dla {file_path.name}")
                    extracted_content = f"Video processing cancelled dla {file_path.name}"
                    llm_summary = "Przetwarzanie przerwane - anulowane"
                    
            else:
                # Fallback jeÅ›li Jarvis nie jest dostÄ™pny
                extracted_content = f"Fallback: Video {file_path.name} (Jarvis ekstraktory niedostÄ™pne)"
                llm_summary = "Ekstrakcja niedostÄ™pna - wymagane poprawne importy Jarvis"
            
            # GPU memory po przetwarzaniu
            gpu_after = self.monitor_gpu_memory()
            processing_time = time.time() - start_time
            
            result = {
                'file_path': str(file_path),
                'file_type': 'video',
                'file_size_mb': file_path.stat().st_size / (1024 * 1024),
                'processing_time': processing_time,
                'status': 'success',
                'extracted_text': extracted_content[:500],
                'llm_summary': llm_summary[:500],
                'gpu_memory_before': gpu_before,
                'gpu_memory_after': gpu_after,
                'error': None
            }
            
            logger.info(f"âœ… Video przetworzony: {processing_time:.2f}s")
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"âŒ BÅ‚Ä…d przetwarzania video {file_path.name}: {e}")
            
            return {
                'file_path': str(file_path),
                'file_type': 'video',
                'file_size_mb': file_path.stat().st_size / (1024 * 1024),
                'processing_time': processing_time,
                'status': 'failed',
                'extracted_text': f'BÅ‚Ä…d przetwarzania: {str(e)}',
                'llm_summary': '',
                'gpu_memory_before': gpu_before,
                'gpu_memory_after': self.monitor_gpu_memory(),
                'error': str(e)
            }

    async def process_batch(self, selected_files: Dict[str, List[Path]]):
        """Przetwarzanie wsadowe plikÃ³w - PRAWDZIWE"""
        logger.info("ðŸš€ ROZPOCZÄ˜CIE PRAWDZIWEGO PRZETWARZANIA WSADOWEGO")
        print("="*60)
        
        self.stats['start_time'] = datetime.now()
        
        # Flatten all files
        all_files = []
        for file_path in selected_files['video']:
            all_files.append((file_path, 'video'))
        for file_path in selected_files['image']:
            all_files.append((file_path, 'image'))
        
        self.stats['total_files'] = len(all_files)
        
        # Process files in batches (RTX 4050 optimized)
        video_batch_size = 2  # Reduced for real processing
        image_batch_size = 4  # Reduced for real processing
        
        # Process videos first (they use more memory)
        video_files = [(f, t) for f, t in all_files if t == 'video']
        for i in range(0, len(video_files), video_batch_size):
            batch = video_files[i:i + video_batch_size]
            logger.info(f"ðŸŽ¬ Przetwarzanie batch video {i//video_batch_size + 1}: {len(batch)} plikÃ³w")
            
            # Process sequentially for stability
            for file_path, file_type in batch:
                result = await self.process_video(file_path)
                self.results.append(result)
                
                if result['status'] == 'success':
                    self.stats['processed_files'] += 1
                else:
                    self.stats['failed_files'] += 1
                self.stats['processing_times'].append(result['processing_time'])
                
                # Clear GPU memory after each file
                torch.cuda.empty_cache()
            
            logger.info("ðŸ§¹ GPU memory cleared")
        
        # Process images
        image_files = [(f, t) for f, t in all_files if t == 'image']
        for i in range(0, len(image_files), image_batch_size):
            batch = image_files[i:i + image_batch_size]
            logger.info(f"ðŸ–¼ï¸ Przetwarzanie batch obrazÃ³w {i//image_batch_size + 1}: {len(batch)} plikÃ³w")
            
            # Process sequentially for stability
            for file_path, file_type in batch:
                result = await self.process_image(file_path)
                self.results.append(result)
                
                if result['status'] == 'success':
                    self.stats['processed_files'] += 1
                else:
                    self.stats['failed_files'] += 1
                self.stats['processing_times'].append(result['processing_time'])
                
                # Clear GPU memory after each file
                torch.cuda.empty_cache()
            
            logger.info("ðŸ§¹ GPU memory cleared")
        
        self.stats['end_time'] = datetime.now()

    def generate_report(self):
        """Generowanie raportu z wynikÃ³w"""
        logger.info("ðŸ“Š GENEROWANIE RAPORTU")
        print("="*50)
        
        # Calculate statistics
        total_time = (self.stats['end_time'] - self.stats['start_time']).total_seconds()
        avg_processing_time = sum(self.stats['processing_times']) / len(self.stats['processing_times']) if self.stats['processing_times'] else 0
        success_rate = (self.stats['processed_files'] / self.stats['total_files']) * 100 if self.stats['total_files'] > 0 else 0
        
        # Create report
        report = {
            'timestamp': datetime.now().isoformat(),
            'processing_type': 'REAL' if self.real_processing else 'FALLBACK',
            'jarvis_available': JARVIS_AVAILABLE,
            'statistics': {
                'total_files': self.stats['total_files'],
                'processed_files': self.stats['processed_files'],
                'failed_files': self.stats['failed_files'],
                'success_rate': success_rate,
                'total_time_seconds': total_time,
                'average_processing_time': avg_processing_time,
                'files_per_minute': (self.stats['processed_files'] / total_time) * 60 if total_time > 0 else 0
            },
            'results': self.results
        }
        
        # Save JSON report
        with open('output/batch_processing_report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        # Print summary
        print("\n" + "="*60)
        print("ðŸŽ¯ PODSUMOWANIE PRAWDZIWEGO PRZETWARZANIA")
        print("="*60)
        print(f"ðŸ“Š Typ przetwarzania: {'PRAWDZIWE' if self.real_processing else 'FALLBACK'}")
        print(f"ðŸ“Š Jarvis dostÄ™pny: {'TAK' if JARVIS_AVAILABLE else 'NIE'}")
        print(f"ðŸ“Š ÅÄ…czny czas: {total_time:.2f} sekund")
        print(f"ðŸ“Š Przetworzone pliki: {self.stats['processed_files']}/{self.stats['total_files']}")
        print(f"ðŸ“Š Sukces rate: {success_rate:.1f}%")
        print(f"ðŸ“Š Åšredni czas na plik: {avg_processing_time:.2f} sekund")
        
        # Show sample results
        print(f"\nðŸ“‹ PRZYKÅADOWE WYNIKI:")
        print("="*60)
        for i, result in enumerate(self.results[:3], 1):
            status = "âœ…" if result['status'] == 'success' else "âŒ"
            print(f"{i}. {status} [{result['file_type'].upper()}] {Path(result['file_path']).name}")
            print(f"   Czas: {result['processing_time']:.2f}s")
            print(f"   TreÅ›Ä‡: {result['extracted_text'][:100]}...")
            if result['llm_summary']:
                print(f"   AI: {result['llm_summary'][:100]}...")
            print()
        
        logger.info(f"ðŸ“‹ Raport zapisany w: output/batch_processing_report.json")
        return report

    async def save_to_knowledge_base(self, file_path: Path, extraction_result, llm_summary: str, content_type: str) -> str:
        """Zapisuje wyniki do Knowledge Base"""
        try:
            # Generowanie unikalnego ID lekcji
            from datetime import datetime
            import hashlib
            
            file_hash = hashlib.md5(str(file_path).encode()).hexdigest()[:8]
            lesson_id = f"{content_type}_{file_hash}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            # Przygotowanie danych lekcji
            lesson_data = {
                'lesson_id': lesson_id,
                'title': extraction_result.title,
                'summary': llm_summary[:500],  # Ograniczenie dÅ‚ugoÅ›ci
                'content': extraction_result.content,
                'source_file': str(file_path),
                'content_type': content_type,
                'file_size_mb': file_path.stat().st_size / (1024 * 1024),
                'extraction_metadata': extraction_result.metadata,
                'confidence': extraction_result.confidence,
                'language': extraction_result.language,
                'created_at': datetime.now().isoformat(),
                'tags': self._generate_tags(extraction_result, content_type),
                'categories': self._generate_categories(extraction_result, content_type)
            }
            
            # Zapisanie do pliku (jako backup) i bazy
            kb_file = self.output_folder / f"knowledge_base_{lesson_id}.json"
            with open(kb_file, 'w', encoding='utf-8') as f:
                json.dump(lesson_data, f, indent=2, ensure_ascii=False)
            
            # PrÃ³ba zapisu do rzeczywistej bazy Knowledge Base
            try:
                if hasattr(self, 'knowledge_base'):
                    # Dodanie lekcji do Knowledge Base
                    self.knowledge_base.add_lesson(
                        lesson_id=lesson_id,
                        title=extraction_result.title,
                        summary=llm_summary[:500],
                        content_path=str(kb_file),
                        tags=lesson_data['tags'],
                        categories=lesson_data['categories'],
                        difficulty='intermediate',  # Default
                        duration=10,  # Estimated 10 minutes
                        topics_count=1,
                        metadata=lesson_data['extraction_metadata']
                    )
                    logger.info(f"   âœ… Dodano do Knowledge Base: {lesson_id}")
            except Exception as kb_error:
                logger.warning(f"   âš ï¸ BÅ‚Ä…d Knowledge Base, zapisano tylko do pliku: {kb_error}")
            
            return lesson_id
            
        except Exception as e:
            logger.error(f"BÅ‚Ä…d zapisu do Knowledge Base: {e}")
            return f"error_{datetime.now().strftime('%H%M%S')}"
    
    def _generate_tags(self, extraction_result, content_type: str) -> List[str]:
        """Generuje tagi na podstawie treÅ›ci"""
        tags = [content_type, "auto-extracted"]
        
        content = extraction_result.content.lower()
        
        # Dodaj tagi na podstawie treÅ›ci
        tag_keywords = {
            "matematyka": ['rÃ³wnanie', 'funkcja', 'wykres', 'liczba', 'algebra'],
            "programowanie": ['kod', 'python', 'javascript', 'function', 'class', 'algorytm'],
            "nauka": ['eksperyment', 'badanie', 'teoria', 'hipoteza', 'analiza'],
            "jÄ™zyk": ['gramatyka', 'sÅ‚ownictwo', 'tekst', 'jÄ™zyk', 'literatura'],
            "historia": ['data', 'wydarzenie', 'historia', 'chronologia'],
            "fizyka": ['siÅ‚a', 'energia', 'masa', 'prÄ™dkoÅ›Ä‡', 'fizyka'],
            "chemia": ['reakcja', 'zwiÄ…zek', 'pierwiastek', 'chemia', 'molekuÅ‚a']
        }
        
        for tag, keywords in tag_keywords.items():
            if any(keyword in content for keyword in keywords):
                tags.append(tag)
        
        # Dodaj tagi na podstawie metadanych
        if extraction_result.confidence > 0.8:
            tags.append("high-confidence")
        elif extraction_result.confidence > 0.5:
            tags.append("medium-confidence")
        else:
            tags.append("low-confidence")
        
        return tags
    
    def _generate_categories(self, extraction_result, content_type: str) -> List[str]:
        """Generuje kategorie na podstawie treÅ›ci"""
        categories = []
        
        content = extraction_result.content.lower()
        
        # GÅ‚Ã³wne kategorie edukacyjne
        if any(word in content for word in ['matematyka', 'liczba', 'rÃ³wnanie', 'funkcja']):
            categories.append("Matematyka")
        elif any(word in content for word in ['kod', 'python', 'programowanie', 'algorytm']):
            categories.append("Informatyka")
        elif any(word in content for word in ['jÄ™zyk', 'gramatyka', 'tekst', 'literatura']):
            categories.append("JÄ™zyki")
        elif any(word in content for word in ['fizyka', 'siÅ‚a', 'energia', 'masa']):
            categories.append("Fizyka")
        elif any(word in content for word in ['chemia', 'reakcja', 'zwiÄ…zek']):
            categories.append("Chemia")
        elif any(word in content for word in ['historia', 'wydarzenie', 'data']):
            categories.append("Historia")
        else:
            categories.append("OgÃ³lne")
        
        # Kategorie na podstawie typu contentu
        if content_type == "video":
            categories.append("MateriaÅ‚y wideo")
        elif content_type == "image":
            categories.append("MateriaÅ‚y wizualne")
        
        return categories if categories else ["Nieskategoryzowane"]

async def main():
    """GÅ‚Ã³wna funkcja testowa"""
    print("ðŸ§ª JARVIS EDU REAL BATCH PROCESSING")
    print("="*60)
    print(f"Test started: {datetime.now()}")
    print("="*60)
    
    # Initialize processor
    processor = RealBatchProcessor()
    
    # Select random files
    selected_files = processor.select_random_files(15)
    
    # Process files
    await processor.process_batch(selected_files)
    
    # Generate report
    report = processor.generate_report()
    
    print("\nðŸŽ‰ REAL BATCH PROCESSING COMPLETED!")

if __name__ == '__main__':
    asyncio.run(main()) 