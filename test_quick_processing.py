#!/usr/bin/env python3
"""Quick Test - 3 pliki aby sprawdziƒá naprawki"""

import os
import sys
import random
import asyncio
import time
from pathlib import Path
from datetime import datetime
import logging
import json
import torch
from typing import List, Dict, Any
import requests

# Jarvis imports
try:
    from jarvis_edu.core.config import get_settings
    from jarvis_edu.extractors.enhanced_image_extractor import EnhancedImageExtractor
    from jarvis_edu.extractors.enhanced_video_extractor import EnhancedVideoExtractor
    from jarvis_edu.extractors.enhanced_audio_extractor import EnhancedAudioExtractor
    from jarvis_edu.processors.lm_studio import LMStudioProcessor
    from jarvis_edu.storage.knowledge_base import KnowledgeBase
    JARVIS_AVAILABLE = True
except ImportError as e:
    print(f"‚ö†Ô∏è B≈ÇƒÖd importu Jarvis: {e}")
    JARVIS_AVAILABLE = False

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/quick_test.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class QuickTestProcessor:
    def __init__(self):
        self.media_folder = Path("C:/Users/barto/OneDrive/Pulpit/mediapobrane/pobrane_media")
        self.output_folder = Path("output")
        self.output_folder.mkdir(exist_ok=True)
        
        if JARVIS_AVAILABLE:
            try:
                self.settings = get_settings()
                self.image_extractor = EnhancedImageExtractor()
                self.video_extractor = EnhancedVideoExtractor()
                self.audio_extractor = EnhancedAudioExtractor()
                self.llm_processor = LMStudioProcessor()
                self.knowledge_base = KnowledgeBase()
                self.real_processing = True
                logger.info("‚úÖ Jarvis ekstraktory zainicjalizowane")
            except Exception as e:
                logger.error(f"‚ùå B≈ÇƒÖd inicjalizacji Jarvis: {e}")
                self.real_processing = False
        else:
            self.real_processing = False
        
        self.results = []

    def monitor_gpu_memory(self) -> Dict[str, Any]:
        """Monitor GPU memory usage"""
        if torch.cuda.is_available():
            allocated = torch.cuda.memory_allocated() / 1024**3
            reserved = torch.cuda.memory_reserved() / 1024**3
            total = torch.cuda.get_device_properties(0).total_memory / 1024**3
            
            return {
                'allocated_gb': allocated,
                'reserved_gb': reserved,
                'free_gb': total - reserved,
                'total_gb': total,
                'usage_percent': (reserved / total) * 100
            }
        return {
            'allocated_gb': 0,
            'reserved_gb': 0,
            'free_gb': 0,
            'total_gb': 0,
            'usage_percent': 0
        }

    async def save_to_knowledge_base(self, file_path: Path, extraction_result, llm_summary: str, content_type: str) -> str:
        """Zapisuje wyniki do Knowledge Base"""
        try:
            # Generowanie unikalnego ID lekcji
            from datetime import datetime
            import hashlib
            
            file_hash = hashlib.md5(str(file_path).encode()).hexdigest()[:8]
            lesson_id = f"{content_type}_{file_hash}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            # Przygotowanie danych lekcji
            lesson_data = {
                'lesson_id': lesson_id,
                'title': extraction_result.title,
                'summary': llm_summary[:500],  # Ograniczenie d≈Çugo≈õci
                'content': extraction_result.content,
                'source_file': str(file_path),
                'content_type': content_type,
                'file_size_mb': file_path.stat().st_size / (1024 * 1024),
                'extraction_metadata': extraction_result.metadata,
                'confidence': extraction_result.confidence,
                'language': extraction_result.language,
                'created_at': datetime.now().isoformat(),
                'tags': self._generate_tags(extraction_result, content_type),
                'categories': self._generate_categories(extraction_result, content_type)
            }
            
            # Zapisanie do pliku (jako backup) i bazy
            kb_file = self.output_folder / f"knowledge_base_{lesson_id}.json"
            with open(kb_file, 'w', encoding='utf-8') as f:
                json.dump(lesson_data, f, indent=2, ensure_ascii=False)
            
            # Pr√≥ba zapisu do rzeczywistej bazy Knowledge Base
            try:
                if hasattr(self, 'knowledge_base') and self.knowledge_base:
                    # Dodanie lekcji do Knowledge Base
                    self.knowledge_base.add_lesson(
                        lesson_id=lesson_id,
                        title=extraction_result.title,
                        summary=llm_summary[:500],
                        content_path=str(kb_file),
                        tags=lesson_data['tags'],
                        categories=lesson_data['categories'],
                        difficulty='intermediate',  # Default
                        duration=10,  # Estimated 10 minutes
                        topics_count=1,
                        metadata=lesson_data['extraction_metadata']
                    )
                    logger.info(f"   ‚úÖ Dodano do Knowledge Base database: {lesson_id}")
            except Exception as kb_error:
                logger.warning(f"   ‚ö†Ô∏è B≈ÇƒÖd Knowledge Base database, zapisano tylko do pliku: {kb_error}")
            
            return lesson_id
            
        except Exception as e:
            logger.error(f"B≈ÇƒÖd zapisu do Knowledge Base: {e}")
            from datetime import datetime
            return f"error_{datetime.now().strftime('%H%M%S')}"
    
    def _generate_tags(self, extraction_result, content_type: str) -> List[str]:
        """Generuje tagi na podstawie tre≈õci"""
        tags = [content_type, "auto-extracted", "quick-test"]
        
        content = extraction_result.content.lower()
        
        # Dodaj tagi na podstawie tre≈õci
        tag_keywords = {
            "matematyka": ['r√≥wnanie', 'funkcja', 'wykres', 'liczba', 'algebra', 'geometria'],
            "programowanie": ['kod', 'python', 'javascript', 'function', 'class', 'algorytm', 'script'],
            "nauka": ['eksperyment', 'badanie', 'teoria', 'hipoteza', 'analiza', 'research'],
            "jƒôzyk": ['gramatyka', 's≈Çownictwo', 'tekst', 'jƒôzyk', 'literatura', 't≈Çumaczenie'],
            "historia": ['data', 'wydarzenie', 'historia', 'chronologia', 'period', 'century'],
            "fizyka": ['si≈Ça', 'energia', 'masa', 'prƒôdko≈õƒá', 'fizyka', 'physics', 'force'],
            "chemia": ['reakcja', 'zwiƒÖzek', 'pierwiastek', 'chemia', 'moleku≈Ça', 'chemistry'],
            "edukacja": ['lekcja', 'uczenie', 'nauka', 'student', 'nauczyciel', 'szko≈Ça']
        }
        
        for tag, keywords in tag_keywords.items():
            if any(keyword in content for keyword in keywords):
                tags.append(tag)
        
        # Dodaj tagi na podstawie metadanych
        if extraction_result.confidence > 0.8:
            tags.append("high-confidence")
        elif extraction_result.confidence > 0.5:
            tags.append("medium-confidence")
        else:
            tags.append("low-confidence")
        
        return tags
    
    def _generate_categories(self, extraction_result, content_type: str) -> List[str]:
        """Generuje kategorie na podstawie tre≈õci"""
        categories = []
        
        content = extraction_result.content.lower()
        
        # G≈Ç√≥wne kategorie edukacyjne
        if any(word in content for word in ['matematyka', 'liczba', 'r√≥wnanie', 'funkcja', 'algebra']):
            categories.append("Matematyka")
        elif any(word in content for word in ['kod', 'python', 'programowanie', 'algorytm', 'script']):
            categories.append("Informatyka")
        elif any(word in content for word in ['jƒôzyk', 'gramatyka', 'tekst', 'literatura', 's≈Çowo']):
            categories.append("Jƒôzyki")
        elif any(word in content for word in ['fizyka', 'si≈Ça', 'energia', 'masa', 'physics']):
            categories.append("Fizyka")
        elif any(word in content for word in ['chemia', 'reakcja', 'zwiƒÖzek', 'chemistry']):
            categories.append("Chemia")
        elif any(word in content for word in ['historia', 'wydarzenie', 'data', 'period']):
            categories.append("Historia")
        elif any(word in content for word in ['biologia', 'organizm', 'kom√≥rka', 'dna']):
            categories.append("Biologia")
        else:
            categories.append("Og√≥lne")
        
        # Kategorie na podstawie typu contentu
        if content_type == "video":
            categories.append("Materia≈Çy wideo")
        elif content_type == "image":
            categories.append("Materia≈Çy wizualne")
        elif content_type == "audio":
            categories.append("Materia≈Çy audio")
        
        return categories if categories else ["Nieskategoryzowane"]

    def select_test_files(self) -> Dict[str, List[Path]]:
        """Wybiera 3 ma≈Çe pliki do testu"""
        logger.info("üé≤ WYBIERANIE 3 MA≈ÅYCH PLIK√ìW DO TESTU")
        print("="*50)
        
        all_files = list(self.media_folder.rglob("*"))
        all_files = [f for f in all_files if f.is_file()]
        
        # Filtruj ma≈Çe pliki (< 5MB)
        video_extensions = {'.mp4', '.avi', '.mkv', '.mov', '.wmv', '.flv', '.webm'}
        image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff', '.webp'}
        
        small_videos = [f for f in all_files 
                       if f.suffix.lower() in video_extensions 
                       and f.stat().st_size < 5 * 1024 * 1024]  # < 5MB
        
        small_images = [f for f in all_files 
                       if f.suffix.lower() in image_extensions 
                       and f.stat().st_size < 1 * 1024 * 1024]  # < 1MB
        
        selected_files = {'video': [], 'image': []}
        
        # Wybierz 2 ma≈Çe video + 1 obraz
        if small_videos:
            selected_files['video'] = random.sample(small_videos, min(2, len(small_videos)))
        if small_images:
            selected_files['image'] = random.sample(small_images, min(1, len(small_images)))
        
        logger.info(f"‚úÖ Wybrano {len(selected_files['video'])} ma≈Çych video")
        logger.info(f"‚úÖ Wybrano {len(selected_files['image'])} ma≈Çych obraz√≥w")
        
        print("\nüìã WYBRANE PLIKI DO TESTU:")
        print("="*50)
        
        for i, file_path in enumerate(selected_files['video'], 1):
            size_mb = file_path.stat().st_size / (1024 * 1024)
            print(f"{i}. [VIDEO] {file_path.name} ({size_mb:.1f} MB)")
        
        for i, file_path in enumerate(selected_files['image'], len(selected_files['video']) + 1):
            size_mb = file_path.stat().st_size / (1024 * 1024)
            print(f"{i}. [IMAGE] {file_path.name} ({size_mb:.1f} MB)")
        
        return selected_files

    async def call_lm_studio(self, prompt: str) -> str:
        """Wywo≈Çanie LM Studio API z naprawkami"""
        try:
            payload = {
                "messages": [
                    {"role": "system", "content": "Jeste≈õ asystentem edukacyjnym. Analizujesz tre≈õci edukacyjne i tworzysz kr√≥tkie podsumowania w jƒôzyku polskim."},
                    {"role": "user", "content": prompt}
                ],
                "max_tokens": 300,
                "temperature": 0.3,
                "stream": False
            }
            
            response = requests.post(
                'http://127.0.0.1:1234/v1/chat/completions',
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                data = response.json()
                if 'choices' in data and data['choices']:
                    if isinstance(data['choices'], list) and len(data['choices']) > 0:
                        choice = data['choices'][0]
                        if 'message' in choice and 'content' in choice['message']:
                            return choice['message']['content'].strip()
                
                return "Podsumowanie AI (struktura odpowiedzi nieoczekiwana)"
            else:
                return f"B≈ÇƒÖd LM Studio (HTTP {response.status_code})"
            
        except Exception as e:
            logger.error(f"B≈ÇƒÖd LM Studio: {e}")
            return f"B≈ÇƒÖd generowania: {str(e)}"

    async def process_file(self, file_path: Path, file_type: str) -> Dict[str, Any]:
        """Przetwarzanie pojedynczego pliku - NAPRAWIONA WERSJA"""
        logger.info(f"üîÑ Przetwarzanie {file_type}: {file_path.name}")
        
        start_time = time.time()
        gpu_before = self.monitor_gpu_memory()
        
        try:
            if self.real_processing:
                if file_type == 'video':
                    # VIDEO PROCESSING z d≈Çugimi timeouts
                    file_size_mb = file_path.stat().st_size / (1024 * 1024)
                    
                    if file_size_mb < 10:
                        timeout_minutes = 15  # 15 minut dla ma≈Çych plik√≥w
                    elif file_size_mb < 50:
                        timeout_minutes = 25  # 25 minut dla ≈õrednich
                    elif file_size_mb < 200:
                        timeout_minutes = 40  # 40 minut dla du≈ºych
                    else:
                        timeout_minutes = 60  # 60 minut dla bardzo du≈ºych
                    
                    logger.info(f"   ‚è∞ Video timeout: {timeout_minutes} minut dla {file_size_mb:.1f}MB")
                    
                    extraction_result = await asyncio.wait_for(
                        self.video_extractor.extract(str(file_path)),
                        timeout=timeout_minutes * 60
                    )
                    
                elif file_type == 'image':
                    # IMAGE PROCESSING z poprawkami OCR
                    logger.info(f"   üñºÔ∏è Uruchamianie zaawansowanego OCR...")
                    
                    # Ustaw PATH dla Tesseract
                    import pytesseract
                    pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'
                    
                    extraction_result = await asyncio.wait_for(
                        self.image_extractor.extract(str(file_path)),
                        timeout=600  # 10 minut dla obraz√≥w (complex OCR)
                    )
                    
                else:
                    raise ValueError(f"Nieobs≈Çugiwany typ: {file_type}")
                
                # POPRAWKA: ExtractedContent to dataclass, nie dictionary
                extracted_content = extraction_result.content
                
                if extracted_content and len(extracted_content.strip()) > 5:
                    # Enhanced LM Studio prompt
                    if file_type == 'video':
                        prompt = f"""
                        ANALIZA VIDEO EDUKACYJNEGO:

                        Tytu≈Ç: {extraction_result.title}
                        Transkrypcja: {extracted_content[:1500]}
                        Metadane: {extraction_result.metadata}

                        Stw√≥rz strukturalne podsumowanie (max 400 s≈Ç√≥w) w jƒôzyku polskim:
                        1. G≈Ç√≥wne tematy omawiane w video
                        2. Kluczowe pojƒôcia i definicje
                        3. Praktyczne zastosowania
                        4. Rekomendacje dla uczni√≥w
                        """
                    else:  # image
                        prompt = f"""
                        ANALIZA OBRAZU/TEKSTU EDUKACYJNEGO:

                        Tytu≈Ç: {extraction_result.title}
                        Wyodrƒôbniony tekst: {extracted_content}
                        Metadane: {extraction_result.metadata}

                        Stw√≥rz strukturalne podsumowanie (max 250 s≈Ç√≥w) w jƒôzyku polskim:
                        1. Rodzaj materia≈Çu (diagram, tekst, schemat, etc.)
                        2. G≈Ç√≥wne informacje zawarte
                        3. Kontekst edukacyjny
                        4. Mo≈ºliwe zastosowania w nauce
                        """
                    
                    logger.info(f"   üß† Generowanie AI podsumowania...")
                    llm_summary = await asyncio.wait_for(
                        self.call_lm_studio(prompt),
                        timeout=90  # 1.5 minuty na LLM
                    )
                    
                    # üî• ZAPISZ DO KNOWLEDGE BASE
                    try:
                        lesson_id = await self.save_to_knowledge_base(
                            file_path=file_path,
                            extraction_result=extraction_result,
                            llm_summary=llm_summary,
                            content_type=file_type
                        )
                        logger.info(f"   üíæ Zapisano do Knowledge Base: {lesson_id}")
                    except Exception as e:
                        logger.error(f"   ‚ùå B≈ÇƒÖd zapisu do KB: {e}")
                        
                else:
                    if file_type == 'image':
                        extracted_content = f"OCR nie wykry≈Ç tekstu w {file_path.name} (mo≈ºliwe zdjƒôcie bez tekstu)"
                        llm_summary = "Brak tekstu do analizy - prawdopodobnie materia≈Ç wizualny bez tre≈õci tekstowych"
                    else:
                        extracted_content = f"Brak audio/transkrypcji w {file_path.name}"
                        llm_summary = "Brak tre≈õci do podsumowania"
                    
            else:
                extracted_content = f"Fallback: {file_path.name} (Jarvis niedostƒôpny)"
                llm_summary = "Fallback processing"
            
            gpu_after = self.monitor_gpu_memory()
            processing_time = time.time() - start_time
            
            result = {
                'file_path': str(file_path),
                'file_type': file_type,
                'file_size_mb': file_path.stat().st_size / (1024 * 1024),
                'processing_time': processing_time,
                'status': 'success',
                'extracted_text': extracted_content[:500],
                'llm_summary': llm_summary[:500],
                'gpu_memory_before': gpu_before,
                'gpu_memory_after': gpu_after,
                'error': None
            }
            
            logger.info(f"‚úÖ {file_type} przetworzony: {processing_time:.2f}s")
            return result
            
        except asyncio.TimeoutError:
            processing_time = time.time() - start_time
            timeout_msg = f"‚è∞ Timeout dla {file_path.name} (>{timeout_minutes if file_type == 'video' else '10'} minut)"
            logger.error(timeout_msg)
            
            return {
                'file_path': str(file_path),
                'file_type': file_type,
                'file_size_mb': file_path.stat().st_size / (1024 * 1024),
                'processing_time': processing_time,
                'status': 'timeout',
                'extracted_text': timeout_msg,
                'llm_summary': '',
                'gpu_memory_before': gpu_before,
                'gpu_memory_after': self.monitor_gpu_memory(),
                'error': 'timeout'
            }
            
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"‚ùå B≈ÇƒÖd {file_path.name}: {e}")
            
            return {
                'file_path': str(file_path),
                'file_type': file_type,
                'file_size_mb': file_path.stat().st_size / (1024 * 1024),
                'processing_time': processing_time,
                'status': 'failed',
                'extracted_text': f'B≈ÇƒÖd: {str(e)}',
                'llm_summary': '',
                'gpu_memory_before': gpu_before,
                'gpu_memory_after': self.monitor_gpu_memory(),
                'error': str(e)
            }

    async def process_all_files(self, selected_files: Dict[str, List[Path]]):
        """Przetwarzanie wszystkich plik√≥w"""
        logger.info("üöÄ ROZPOCZƒòCIE SZYBKIEGO TESTU")
        print("="*50)
        
        # Flatten all files
        all_files = []
        for file_path in selected_files['video']:
            all_files.append((file_path, 'video'))
        for file_path in selected_files['image']:
            all_files.append((file_path, 'image'))
        
        # Process sequentially for stability
        for file_path, file_type in all_files:
            result = await self.process_file(file_path, file_type)
            self.results.append(result)
            
            # Clear GPU memory
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

    def generate_report(self):
        """Generowanie raportu"""
        logger.info("üìä GENEROWANIE RAPORTU TESTU")
        print("="*50)
        
        # Statistics
        total_files = len(self.results)
        success_files = len([r for r in self.results if r['status'] == 'success'])
        failed_files = len([r for r in self.results if r['status'] != 'success'])
        avg_time = sum(r['processing_time'] for r in self.results) / total_files if total_files > 0 else 0
        
        # Create report
        report = {
            'timestamp': datetime.now().isoformat(),
            'test_type': 'QUICK_TEST',
            'processing_type': 'REAL' if self.real_processing else 'FALLBACK',
            'jarvis_available': JARVIS_AVAILABLE,
            'statistics': {
                'total_files': total_files,
                'success_files': success_files,
                'failed_files': failed_files,
                'success_rate': (success_files / total_files) * 100 if total_files > 0 else 0,
                'average_processing_time': avg_time
            },
            'results': self.results
        }
        
        # Save report
        with open('output/quick_test_report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        # Print summary
        print("\n" + "="*60)
        print("üéØ PODSUMOWANIE SZYBKIEGO TESTU")
        print("="*60)
        print(f"üìä Typ: {'PRAWDZIWE' if self.real_processing else 'FALLBACK'}")
        print(f"üìä Jarvis: {'DOSTƒòPNY' if JARVIS_AVAILABLE else 'NIEDOSTƒòPNY'}")
        print(f"üìä Pliki: {success_files}/{total_files} sukces")
        print(f"üìä ≈öredni czas: {avg_time:.2f}s")
        
        print(f"\nüìã WYNIKI:")
        print("="*60)
        for i, result in enumerate(self.results, 1):
            status = "‚úÖ" if result['status'] == 'success' else "‚ùå"
            print(f"{i}. {status} [{result['file_type'].upper()}] {Path(result['file_path']).name}")
            print(f"   Czas: {result['processing_time']:.2f}s | Status: {result['status']}")
            if result['extracted_text']:
                print(f"   Tre≈õƒá: {result['extracted_text'][:80]}...")
            if result['llm_summary']:
                print(f"   AI: {result['llm_summary'][:80]}...")
            print()
        
        logger.info("üìã Raport zapisany w: output/quick_test_report.json")
        return report

async def main():
    """G≈Ç√≥wna funkcja testu"""
    print("üß™ JARVIS EDU QUICK TEST - 3 PLIKI")
    print("="*60)
    print(f"Test started: {datetime.now()}")
    print("="*60)
    
    processor = QuickTestProcessor()
    selected_files = processor.select_test_files()
    
    if not selected_files['video'] and not selected_files['image']:
        print("‚ùå Brak ma≈Çych plik√≥w do testu!")
        return
    
    await processor.process_all_files(selected_files)
    report = processor.generate_report()
    
    print("\nüéâ QUICK TEST COMPLETED!")

if __name__ == '__main__':
    asyncio.run(main()) 