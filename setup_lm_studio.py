#!/usr/bin/env python3
"""
Setup i konfiguracja LM Studio dla Jarvis EDU
=============================================

Skrypt sprawdza, konfiguruje i pomaga w instalacji LM Studio
"""

import sys
import json
import asyncio
import requests
from pathlib import Path
from rich.console import Console
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn
from rich.table import Table
from rich.prompt import Prompt, Confirm

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent))

try:
    from jarvis_edu.processors.lm_studio import LMStudioProcessor
    from jarvis_edu.core.logger import get_logger
except ImportError as e:
    print(f"‚ùå Import error: {e}")
    print("üí° Make sure you're in the project directory")
    sys.exit(1)

console = Console()
logger = get_logger("lm_studio_setup")


class LMStudioConfigurator:
    """LM Studio configurator and helper."""
    
    def __init__(self):
        self.lm_studio = LMStudioProcessor()
        self.recommended_models = [
            {
                "name": "mistral-7b-instruct-v0.3",
                "size": "4.4 GB",
                "description": "Szybki i skuteczny model do zada≈Ñ edukacyjnych",
                "good_for": ["Tworzenie lekcji", "Analiza tre≈õci", "Szybkie odpowiedzi"],
                "requirements": "8 GB RAM"
            },
            {
                "name": "llama-3.1-8b-instruct",
                "size": "4.7 GB", 
                "description": "Bardzo dobry model og√≥lnego u≈ºytku",
                "good_for": ["Szczeg√≥≈Çowa analiza", "Z≈Ço≈ºone zadania", "Wysokiej jako≈õci tre≈õƒá"],
                "requirements": "12 GB RAM"
            },
            {
                "name": "phi-3-mini-4k-instruct",
                "size": "2.3 GB",
                "description": "Lekki model dla s≈Çabszych komputer√≥w",
                "good_for": ["Podstawowa analiza", "Szybkie przetwarzanie", "Ma≈Ço zasob√≥w"],
                "requirements": "4 GB RAM"
            }
        ]
    
    async def check_connection(self):
        """Sprawdz po≈ÇƒÖczenie z LM Studio."""
        console.print("\n[bold]üîç Sprawdzanie po≈ÇƒÖczenia z LM Studio[/bold]")
        
        try:
            is_available = await self.lm_studio.is_available()
            
            if is_available:
                console.print("[green]‚úÖ LM Studio dzia≈Ça[/green]")
                
                connection_info = await self.lm_studio.test_connection()
                console.print(f"[blue]üì° Endpoint: {connection_info['endpoint']}[/blue]")
                
                models = connection_info.get("models", [])
                if models:
                    console.print(f"[green]üß† Za≈Çadowanych modeli: {len(models)}[/green]")
                    return True, models
                else:
                    console.print("[yellow]‚ö†Ô∏è  Brak za≈Çadowanych modeli[/yellow]")
                    return True, []
            else:
                console.print("[red]‚ùå LM Studio nie odpowiada[/red]")
                return False, []
                
        except Exception as e:
            console.print(f"[red]‚ùå B≈ÇƒÖd po≈ÇƒÖczenia: {e}[/red]")
            return False, []
    
    def show_installation_guide(self):
        """Poka≈º przewodnik instalacji LM Studio."""
        console.print("\n[bold blue]üì• Przewodnik instalacji LM Studio[/bold blue]")
        
        steps = [
            "1. üåê Przejd≈∫ na stronƒô: https://lmstudio.ai/",
            "2. üì• Pobierz LM Studio dla Windows",
            "3. üîß Zainstaluj aplikacjƒô (wymaga ~500 MB)",
            "4. üöÄ Uruchom LM Studio",
            "5. üß† Pobierz i za≈Çaduj model (patrz rekomendacje poni≈ºej)",
            "6. ‚ñ∂Ô∏è  Uruchom serwer (Local Server)",
            "7. ‚úÖ Sprawd≈∫ po≈ÇƒÖczenie tym skryptem ponownie"
        ]
        
        for step in steps:
            console.print(step)
        
        console.print(Panel(
            "[bold]‚ö†Ô∏è  Wymagania systemowe:[/bold]\n"
            "‚Ä¢ Windows 10/11 (64-bit)\n"
            "‚Ä¢ 8+ GB RAM (dla wiƒôkszo≈õci modeli)\n"
            "‚Ä¢ 5-10 GB wolnego miejsca na dysku\n"
            "‚Ä¢ Zalecane: GPU z 4+ GB VRAM",
            title="Wymagania",
            border_style="yellow"
        ))
    
    def show_model_recommendations(self):
        """Poka≈º rekomendowane modele."""
        console.print("\n[bold]üß† Rekomendowane modele[/bold]")
        
        table = Table(title="Modele do pobrania w LM Studio")
        table.add_column("Model", style="cyan", no_wrap=True)
        table.add_column("Rozmiar", style="yellow")
        table.add_column("Opis", style="white")
        table.add_column("Zastosowanie", style="green")
        table.add_column("Wymagania", style="red")
        
        for model in self.recommended_models:
            table.add_row(
                model["name"],
                model["size"],
                model["description"][:30] + "..." if len(model["description"]) > 30 else model["description"],
                ", ".join(model["good_for"][:2]),
                model["requirements"]
            )
        
        console.print(table)
        
        console.print("\n[bold yellow]üí° Jak pobraƒá model w LM Studio:[/bold yellow]")
        console.print("1. Otw√≥rz zak≈Çadkƒô 'Search' w LM Studio")
        console.print("2. Wyszukaj nazwƒô modelu (np. 'mistral-7b-instruct')")
        console.print("3. Kliknij 'Download' przy wybranym modelu")
        console.print("4. Po pobraniu przejd≈∫ do 'My Models'")
        console.print("5. Kliknij 'Load' przy modelu")
        console.print("6. Przejd≈∫ do 'Local Server' i kliknij 'Start Server'")
    
    async def test_model_performance(self):
        """Testuj wydajno≈õƒá modelu."""
        console.print("\n[bold]üß™ Test wydajno≈õci modelu[/bold]")
        
        test_prompts = [
            {
                "prompt": "Napisz kr√≥tkƒÖ lekcjƒô o podstawach Pythona w formacie JSON z polami: title, summary, content",
                "description": "Test tworzenia lekcji"
            },
            {
                "prompt": "Przeanalizuj ten tekst i wyodrƒôbnij kluczowe tematy: 'Python to jƒôzyk programowania'",
                "description": "Test analizy tekstu"
            }
        ]
        
        for i, test in enumerate(test_prompts, 1):
            console.print(f"\n[blue]Test {i}: {test['description']}[/blue]")
            
            try:
                with Progress(
                    SpinnerColumn(),
                    TextColumn("[progress.description]{task.description}"),
                    console=console,
                ) as progress:
                    task = progress.add_task("Generowanie odpowiedzi...", total=1)
                    
                    import time
                    start_time = time.time()
                    
                    response = await self.lm_studio.generate_lesson_from_prompt(test["prompt"])
                    
                    end_time = time.time()
                    duration = end_time - start_time
                    
                    progress.update(task, completed=1)
                
                if response:
                    console.print(f"[green]‚úÖ Sukces ({duration:.2f}s)[/green]")
                    console.print(f"[dim]Odpowied≈∫: {str(response)[:100]}...[/dim]")
                else:
                    console.print("[yellow]‚ö†Ô∏è  Pusta odpowied≈∫[/yellow]")
                    
            except Exception as e:
                console.print(f"[red]‚ùå B≈ÇƒÖd: {e}[/red]")
    
    def show_server_configuration(self):
        """Poka≈º konfiguracjƒô serwera."""
        console.print("\n[bold]‚öôÔ∏è  Konfiguracja serwera LM Studio[/bold]")
        
        config_tips = [
            "üåê **Port:** 1234 (domy≈õlny, nie zmieniaj bez potrzeby)",
            "üîß **Max Tokens:** 4000-8000 (dla d≈Çu≈ºszych tekst√≥w)",
            "üéØ **Temperature:** 0.3-0.7 (0.3 = bardziej deterministyczne)",
            "‚ö° **GPU Layers:** Maksymalna liczba dla GPU (je≈õli masz)",
            "üß† **Context Length:** 4096+ (dla d≈Çu≈ºszych kontekst√≥w)",
            "üíæ **Thread Count:** Liczba rdzeni CPU - 1"
        ]
        
        for tip in config_tips:
            console.print(tip)
        
        console.print(Panel(
            "[bold]üöÄ Optymalne ustawienia dla Jarvis EDU:[/bold]\n"
            "‚Ä¢ Temperature: 0.3 (stabilne wyniki)\n"
            "‚Ä¢ Max Tokens: 4000 (d≈Çugie lekcje)\n"
            "‚Ä¢ Top P: 0.9\n"
            "‚Ä¢ Frequency Penalty: 0.1\n"
            "‚Ä¢ Presence Penalty: 0.1",
            title="Zalecane ustawienia",
            border_style="green"
        ))
    
    def create_config_files(self):
        """Stw√≥rz pliki konfiguracyjne."""
        console.print("\n[bold]üìÑ Tworzenie plik√≥w konfiguracyjnych[/bold]")
        
        # Aktualizuj config/auto-mode.yaml
        config_path = Path("config/auto-mode.yaml")
        if config_path.exists():
            console.print(f"[blue]‚úÖ Plik konfiguracyjny istnieje: {config_path}[/blue]")
        else:
            console.print("[yellow]‚ö†Ô∏è  Plik konfiguracyjny nie istnieje[/yellow]")
            
        # Stw√≥rz przyk≈Çadowy plik .env je≈õli nie istnieje
        env_path = Path(".env")
        if not env_path.exists():
            env_content = """# Jarvis EDU Environment Configuration
# LM Studio Configuration
LLM__PROVIDER=lmstudio
LLM__ENDPOINT=http://localhost:1234/v1
LLM__MODEL=mistral-7b-instruct
LLM__TEMPERATURE=0.3
LLM__MAX_TOKENS=4000

# Other settings
DEBUG=false
LOG_LEVEL=INFO
"""
            env_path.write_text(env_content, encoding='utf-8')
            console.print(f"[green]‚úÖ Utworzono plik .env: {env_path}[/green]")
        else:
            console.print(f"[blue]‚úÖ Plik .env istnieje: {env_path}[/blue]")
    
    async def run_complete_setup(self):
        """Uruchom kompletny setup."""
        console.print(Panel.fit(
            "[bold blue]ü§ñ LM Studio Setup dla Jarvis EDU[/bold blue]\n"
            "Automatyczna konfiguracja i optymalizacja",
            border_style="blue"
        ))
        
        # 1. Sprawd≈∫ po≈ÇƒÖczenie
        is_connected, models = await self.check_connection()
        
        if not is_connected:
            # 2. Poka≈º przewodnik instalacji
            self.show_installation_guide()
            
            if Confirm.ask("\n‚ùì Czy chcesz zobaczyƒá rekomendowane modele?"):
                self.show_model_recommendations()
            
            console.print("\n[yellow]‚è∏Ô∏è  Uruchom LM Studio i spr√≥buj ponownie[/yellow]")
            return
        
        # 3. Sprawd≈∫ modele
        if not models:
            console.print("\n[yellow]üì• Brak za≈Çadowanych modeli[/yellow]")
            self.show_model_recommendations()
            
            if Confirm.ask("\n‚ùì Czy chcesz zobaczyƒá konfiguracjƒô serwera?"):
                self.show_server_configuration()
            
            console.print("\n[yellow]‚è∏Ô∏è  Za≈Çaduj model w LM Studio i spr√≥buj ponownie[/yellow]")
            return
        
        # 4. Poka≈º za≈Çadowane modele
        console.print(f"\n[green]‚úÖ Znaleziono {len(models)} za≈Çadowanych modeli:[/green]")
        for model in models[:3]:  # Poka≈º pierwsze 3
            console.print(f"  ‚Ä¢ {model.get('id', 'Unknown')}")
        
        # 5. Test wydajno≈õci
        if Confirm.ask("\n‚ùì Czy chcesz przetestowaƒá wydajno≈õƒá modelu?"):
            await self.test_model_performance()
        
        # 6. Konfiguracja
        if Confirm.ask("\n‚ùì Czy chcesz zobaczyƒá optymalne ustawienia serwera?"):
            self.show_server_configuration()
        
        # 7. Pliki konfiguracyjne
        self.create_config_files()
        
        # 8. Podsumowanie
        console.print("\n" + "="*60)
        console.print("[bold green]üéâ LM Studio jest gotowy do pracy![/bold green]")
        console.print("="*60)
        console.print("[green]‚úÖ Po≈ÇƒÖczenie: OK[/green]")
        console.print(f"[green]‚úÖ Modele: {len(models)} za≈Çadowanych[/green]")
        console.print("[green]‚úÖ Konfiguracja: Gotowa[/green]")
        
        console.print("\n[bold]üöÄ Nastƒôpne kroki:[/bold]")
        console.print("1. üîß Uruchom: python test_connections.py")
        console.print("2. üéØ Uruchom Jarvis: python start_jarvis.py")
        console.print("3. üìÅ Wrzuƒá pliki do folderu obserwowanego")
        console.print("4. üéâ Ciesz siƒô automatycznymi lekcjami!")


async def main():
    """Main function."""
    configurator = LMStudioConfigurator()
    
    if len(sys.argv) > 1:
        command = sys.argv[1].lower()
        
        if command == "check":
            await configurator.check_connection()
        elif command == "install":
            configurator.show_installation_guide()
        elif command == "models":
            configurator.show_model_recommendations()
        elif command == "config":
            configurator.show_server_configuration()
        elif command == "test":
            await configurator.test_model_performance()
        else:
            console.print(f"[red]‚ùå Nieznana komenda: {command}[/red]")
            console.print("\n[bold]Dostƒôpne komendy:[/bold]")
            console.print("‚Ä¢ check - sprawd≈∫ po≈ÇƒÖczenie")
            console.print("‚Ä¢ install - przewodnik instalacji") 
            console.print("‚Ä¢ models - rekomendowane modele")
            console.print("‚Ä¢ config - konfiguracja serwera")
            console.print("‚Ä¢ test - test wydajno≈õci")
    else:
        await configurator.run_complete_setup()


if __name__ == "__main__":
    asyncio.run(main()) 